{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT2BERT for CNN/Dailymail",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b10c84feef0e4cf7921d89a6c2a5eb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a80e085427594697bd95ed3f8f20c067",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_adbbdbe8de174014967c97cfae96a2b5",
              "IPY_MODEL_c784d940392d45d08da0c57d32fd1bb3",
              "IPY_MODEL_763e46291005467caabdfc004bb82c2d"
            ]
          }
        },
        "a80e085427594697bd95ed3f8f20c067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adbbdbe8de174014967c97cfae96a2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54c168ea2aa6448b8da52765d2293a9c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35992950b0314576b73aa0caee9035af"
          }
        },
        "c784d940392d45d08da0c57d32fd1bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_89b59df6ea6d4ff3be933ed04dd9aa09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d24c9e095444887925d08af47bfd889"
          }
        },
        "763e46291005467caabdfc004bb82c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d003b390f19d4baf8aa0e9a144b48b4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2500/2500 [00:47&lt;00:00, 53.94ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea870bcc197f4bda88d063c04d43872f"
          }
        },
        "54c168ea2aa6448b8da52765d2293a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35992950b0314576b73aa0caee9035af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89b59df6ea6d4ff3be933ed04dd9aa09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d24c9e095444887925d08af47bfd889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d003b390f19d4baf8aa0e9a144b48b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea870bcc197f4bda88d063c04d43872f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c7a512e5d5243809ba1edd0aa9f6bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ff4c5ec58224034b892c69f8b17494a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6197f1e058c4d479fa458d7e5bf4109",
              "IPY_MODEL_89188dcd0a05416d90101ca3434fdb3f",
              "IPY_MODEL_6a4c24b988f348eea7f973ca65f23221"
            ]
          }
        },
        "8ff4c5ec58224034b892c69f8b17494a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6197f1e058c4d479fa458d7e5bf4109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e127983743dd4ea28fd3ea10fe9e86aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba94a1e4a0a1443888ad525c0993fa5c"
          }
        },
        "89188dcd0a05416d90101ca3434fdb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ad4c15b7ab0445db51b252800658991",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 250,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1254ec12f8204a8490a9504f839f4110"
          }
        },
        "6a4c24b988f348eea7f973ca65f23221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9233fd3a085a4d148e1a404b650add40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/250 [00:04&lt;00:00, 50.83ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21483fdcb1be452f8f3c555e40f00550"
          }
        },
        "e127983743dd4ea28fd3ea10fe9e86aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba94a1e4a0a1443888ad525c0993fa5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ad4c15b7ab0445db51b252800658991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1254ec12f8204a8490a9504f839f4110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9233fd3a085a4d148e1a404b650add40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21483fdcb1be452f8f3c555e40f00550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1d840daa9ef479aa3230145d67bf152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43eb5696b63b4aa282368b36fb5998be",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_89a115ed446242138d0da6501f7e5007",
              "IPY_MODEL_a3a1e190e46d45d1bce24e0624dd44c0",
              "IPY_MODEL_6b49761d3f5149628232365eafb1b89e"
            ]
          }
        },
        "43eb5696b63b4aa282368b36fb5998be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89a115ed446242138d0da6501f7e5007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9165d571ddd049ca852bc98af5d34798",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a9fc2e6adf445369bebc8c5999b8dc7"
          }
        },
        "a3a1e190e46d45d1bce24e0624dd44c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69f75c2a9355476c803fa001aea716ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c30c2c28bd0f4e2185baa257f646e6a4"
          }
        },
        "6b49761d3f5149628232365eafb1b89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_accfba8f0d4d4c5fb2e8a578afbeaf1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:05&lt;00:00,  5.11s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c539ddeb401a45b1954b5fe1be11794f"
          }
        },
        "9165d571ddd049ca852bc98af5d34798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a9fc2e6adf445369bebc8c5999b8dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69f75c2a9355476c803fa001aea716ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c30c2c28bd0f4e2185baa257f646e6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "accfba8f0d4d4c5fb2e8a578afbeaf1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c539ddeb401a45b1954b5fe1be11794f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1F58j028eTV"
      },
      "source": [
        "## **Warm-starting BERT2BERT for CNN/Dailymail**\n",
        "\n",
        "***Note***: This notebook only uses a few training, validation, and test data samples for demonstration purposes. To fine-tune an encoder-decoder model on the full training data, the user should change the training and data preprocessing parameters accordingly as highlighted by the comments.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FO5ESocXvlK"
      },
      "source": [
        "### **Data Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w67vkz3KP9eZ"
      },
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install rouge-score\n",
        "\n",
        "import datasets\n",
        "import transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgTiC0rhMb7C"
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "raw_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Kdw_pP6-6H"
      },
      "source": [
        "encoder_max_length=512\n",
        "decoder_max_length=128\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "  # tokenize the inputs and labels\n",
        "  inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "  outputs = tokenizer(batch[\"highlights\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "  batch[\"input_ids\"] = inputs.input_ids\n",
        "  batch[\"attention_mask\"] = inputs.attention_mask\n",
        "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "  batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "  # because BERT automatically shifts the labels, the labels correspond exactly to `decoder_input_ids`. \n",
        "  # We have to make sure that the PAD token is ignored\n",
        "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "  return batch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29u5kgib7XkK"
      },
      "source": [
        "train_data = raw_data['train'].select(range(20000))\n",
        "val_data = raw_data['validation'].select(range(2000))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DdVV08y7Huv",
        "outputId": "755d6c19-27d8-4040-fec7-834e328763bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b10c84feef0e4cf7921d89a6c2a5eb3c",
            "a80e085427594697bd95ed3f8f20c067",
            "adbbdbe8de174014967c97cfae96a2b5",
            "c784d940392d45d08da0c57d32fd1bb3",
            "763e46291005467caabdfc004bb82c2d",
            "54c168ea2aa6448b8da52765d2293a9c",
            "35992950b0314576b73aa0caee9035af",
            "89b59df6ea6d4ff3be933ed04dd9aa09",
            "7d24c9e095444887925d08af47bfd889",
            "d003b390f19d4baf8aa0e9a144b48b4a",
            "ea870bcc197f4bda88d063c04d43872f"
          ]
        }
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "train_data = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"article\", \"highlights\", \"id\"]\n",
        ")\n",
        "\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b10c84feef0e4cf7921d89a6c2a5eb3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2500 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y2EKJmZ8d6R",
        "outputId": "32043f00-1cda-4ecf-b2d2-1914daa1c328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9c7a512e5d5243809ba1edd0aa9f6bd2",
            "8ff4c5ec58224034b892c69f8b17494a",
            "c6197f1e058c4d479fa458d7e5bf4109",
            "89188dcd0a05416d90101ca3434fdb3f",
            "6a4c24b988f348eea7f973ca65f23221",
            "e127983743dd4ea28fd3ea10fe9e86aa",
            "ba94a1e4a0a1443888ad525c0993fa5c",
            "1ad4c15b7ab0445db51b252800658991",
            "1254ec12f8204a8490a9504f839f4110",
            "9233fd3a085a4d148e1a404b650add40",
            "21483fdcb1be452f8f3c555e40f00550"
          ]
        }
      },
      "source": [
        "val_data = val_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"article\", \"highlights\", \"id\"]\n",
        ")\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c7a512e5d5243809ba1edd0aa9f6bd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEjb026cNC38"
      },
      "source": [
        "### **Warm-starting the Encoder-Decoder Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0UndNoQh8t"
      },
      "source": [
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "bert2bert = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-uncased\", \"bert-base-uncased\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD2jv3GkyjR-"
      },
      "source": [
        "# set special tokens\n",
        "bert2bert.config.decoder_start_token_id = tokenizer.cls_token_id\n",
        "bert2bert.config.eos_token_id = tokenizer.sep_token_id\n",
        "bert2bert.config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# sensible parameters for beam search\n",
        "bert2bert.config.vocab_size = bert2bert.config.decoder.vocab_size\n",
        "bert2bert.config.max_length = 142\n",
        "bert2bert.config.min_length = 56\n",
        "bert2bert.config.no_repeat_ngram_size = 3\n",
        "bert2bert.config.early_stopping = True\n",
        "bert2bert.config.length_penalty = 2.0\n",
        "bert2bert.config.num_beams = 4"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98CLZiTkgzv"
      },
      "source": [
        "### **Fine-Tuning Warm-Started Encoder-Decoder Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZK_gnIzZgTO"
      },
      "source": [
        "For the `EncoderDecoderModel` framework, we will use the `Seq2SeqTrainingArguments` and the `Seq2SeqTrainer`. Let's import them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zkkd66rtsnA"
      },
      "source": [
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPUAgo7pxH24"
      },
      "source": [
        "Also, we need to define a function to correctly compute the ROUGE score during validation. ROUGE is a much better metric to track during training than only language modeling loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2QOAqsM9Nzi",
        "outputId": "d3d59b1c-f7ce-4177-e14f-0ed02e922d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "\n",
        "from datasets import load_metric\n",
        "metric = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ik4hZb2yV-b"
      },
      "source": [
        "Cool! Finally, we start training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaTxUpdzshF"
      },
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    logging_steps=1000,  # set to 1000 for full training\n",
        "    save_steps=500,  # set to 500 for full training\n",
        "    eval_steps=1500,  # set to 8000 for full training\n",
        "    warmup_steps=2000,  # set to 2000 for full training\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    fp16=True, \n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DWQCpJu-lFu"
      },
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=bert2bert,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vas5uYnE-mxD",
        "outputId": "16138fd8-6a6f-4c97-ba3a-4e2c20788982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='5684' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5684/7500 1:52:40 < 36:00, 0.84 it/s, Epoch 2.27/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Gen Len</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.232200</td>\n",
              "      <td>4.492015</td>\n",
              "      <td>18.224900</td>\n",
              "      <td>12.903300</td>\n",
              "      <td>69.857000</td>\n",
              "      <td>718.818500</td>\n",
              "      <td>2.782000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.978900</td>\n",
              "      <td>4.213501</td>\n",
              "      <td>20.979900</td>\n",
              "      <td>14.482200</td>\n",
              "      <td>66.529000</td>\n",
              "      <td>695.516500</td>\n",
              "      <td>2.876000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.694100</td>\n",
              "      <td>4.026018</td>\n",
              "      <td>22.052400</td>\n",
              "      <td>14.884900</td>\n",
              "      <td>66.520500</td>\n",
              "      <td>699.699100</td>\n",
              "      <td>2.858000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1632: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1632: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1632: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7500/7500 2:40:43, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Gen Len</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>4.232200</td>\n",
              "      <td>4.492015</td>\n",
              "      <td>18.224900</td>\n",
              "      <td>12.903300</td>\n",
              "      <td>69.857000</td>\n",
              "      <td>718.818500</td>\n",
              "      <td>2.782000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.978900</td>\n",
              "      <td>4.213501</td>\n",
              "      <td>20.979900</td>\n",
              "      <td>14.482200</td>\n",
              "      <td>66.529000</td>\n",
              "      <td>695.516500</td>\n",
              "      <td>2.876000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>3.694100</td>\n",
              "      <td>4.026018</td>\n",
              "      <td>22.052400</td>\n",
              "      <td>14.884900</td>\n",
              "      <td>66.520500</td>\n",
              "      <td>699.699100</td>\n",
              "      <td>2.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.113800</td>\n",
              "      <td>3.952220</td>\n",
              "      <td>24.085500</td>\n",
              "      <td>16.302300</td>\n",
              "      <td>66.600500</td>\n",
              "      <td>697.306200</td>\n",
              "      <td>2.868000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>3.088700</td>\n",
              "      <td>3.894571</td>\n",
              "      <td>24.628900</td>\n",
              "      <td>16.644000</td>\n",
              "      <td>66.075000</td>\n",
              "      <td>690.425400</td>\n",
              "      <td>2.897000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1632: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1632: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7500, training_loss=3.6303883463541666, metrics={'train_runtime': 9643.8687, 'train_samples_per_second': 0.778, 'total_flos': 56992524134400000, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEEtvEiL6dwo",
        "outputId": "8f03c6d3-dff5-40a7-b96b-f23d55fa507c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-6500  checkpoint-7000  checkpoint-7500  runs  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwQIEhKOrJpl"
      },
      "source": [
        "### **Evaluation**\n",
        "\n",
        "Awesome, we finished training our dummy model. Let's now evaluated the model on the test data. We make use of the dataset's handy `.map()` function to generate a summary of each sample of the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlsAnWDc7Abp"
      },
      "source": [
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = EncoderDecoderModel.from_pretrained(\"./checkpoint-7500\")\n",
        "model.to(\"cuda\")\n",
        "\n",
        "test_data = raw_data['test']\n",
        "\n",
        "# only use 16 training examples for notebook - DELETE LINE FOR FULL TRAINING\n",
        "test_data = test_data.select(range(16))\n",
        "\n",
        "batch_size = 16  # change to 64 for full evaluation"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOoSrwWarJAC"
      },
      "source": [
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    # cut off at BERT max length 512\n",
        "    inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Ngcgun7J5P",
        "outputId": "d85b0dd7-be30-4381-ea27-9ef0f2da6a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e1d840daa9ef479aa3230145d67bf152",
            "43eb5696b63b4aa282368b36fb5998be",
            "89a115ed446242138d0da6501f7e5007",
            "a3a1e190e46d45d1bce24e0624dd44c0",
            "6b49761d3f5149628232365eafb1b89e",
            "9165d571ddd049ca852bc98af5d34798",
            "5a9fc2e6adf445369bebc8c5999b8dc7",
            "69f75c2a9355476c803fa001aea716ce",
            "c30c2c28bd0f4e2185baa257f646e6a4",
            "accfba8f0d4d4c5fb2e8a578afbeaf1b",
            "c539ddeb401a45b1954b5fe1be11794f"
          ]
        }
      },
      "source": [
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:1632: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  next_indices = next_tokens // vocab_size\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1d840daa9ef479aa3230145d67bf152",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1p8wnjE8aqH",
        "outputId": "4517baa8-68f9-4ca2-91f5-5a91bd3f7e47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset(features: {'article': Value(dtype='string', id=None), 'highlights': Value(dtype='string', id=None), 'id': Value(dtype='string', id=None), 'pred': Value(dtype='string', id=None)}, num_rows: 16)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "349Cxn_P7Q39"
      },
      "source": [
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"highlights\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIvRRYAB7ZDu",
        "outputId": "bc423056-6cc1-4f6f-fcdd-9c5133aa89e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(pred_str)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-9Uzu0u7bil",
        "outputId": "b24a661d-837d-4096-a8ce-b1c9dda2fd2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(8):\n",
        "    print(\"Original Text: %s\" % results[i]['article'])\n",
        "    print(\"\\nActual Summary: %s\" % label_str[i])\n",
        "    print(\"\\nPredicted Summary: %s\" % pred_str[i])\n",
        "    print(\"=====================================================================\\n\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: (CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. Coltrane on TV's \"The Dukes of Hazzard,\" died Monday after a brief illness. He was 88. Best died in hospice in Hickory, North Carolina, of complications from pneumonia, said Steve Latshaw, a longtime friend and Hollywood colleague. Although he'd been a busy actor for decades in theater and in Hollywood, Best didn't become famous until 1979, when \"The Dukes of Hazzard's\" cornpone charms began beaming into millions of American homes almost every Friday night. For seven seasons, Best's Rosco P. Coltrane chased the moonshine-running Duke boys back and forth across the back roads of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually ended with him crashing his patrol car. Although Rosco was slow-witted and corrupt, Best gave him a childlike enthusiasm that got laughs and made him endearing. His character became known for his distinctive \"kew-kew-kew\" chuckle and for goofy catchphrases such as \"cuff 'em and stuff 'em!\" upon making an arrest. Among the most popular shows on TV in the early '80s, \"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated series and video games. Several of Best's \"Hazzard\" co-stars paid tribute to the late actor on social media. \"I laughed and learned more from Jimmie in one hour than from anyone else in a whole year,\" co-star John Schneider, who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see him dear friend.\" \"Jimmy Best was the most constantly creative person I have ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a Facebook post. \"Every minute of his long life was spent acting, writing, producing, painting, teaching, fishing, or involved in another of his life's many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James and raised him in rural Indiana. Best served in the Army during World War II before launching his acting career. In the 1950s and 1960s, he accumulated scores of credits, playing a range of colorful supporting characters in such TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and \"Gunsmoke.\" He later appeared in a handful of Burt Reynolds' movies, including \"Hooper\" and \"The End.\" But Best will always be best known for his \"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" Latshaw said. \"I directed two of his feature films, including the recent 'Return of the Killer Shrews,' a sequel he co-wrote and was quite proud of as he had made the first one more than 50 years earlier.\" People we've lost in 2015 . CNN's Stella Chan contributed to this story.\n",
            "\n",
            "Actual Summary: James Best, who played the sheriff on \"The Dukes of Hazzard,\" died Monday at 88 .\n",
            "\"Hazzard\" ran from 1979 to 1985 and was among the most popular shows on TV .\n",
            "\n",
            "Predicted Summary: james travolta was the star of \" hazzard, \" a tv series. he was the co - host of the show's final episode. he also starred in \" hardrd county, \" \" the walking dead, \" and \" the law of the law \"\n",
            "=====================================================================\n",
            "\n",
            "Original Text: (CNN)The attorney for a suburban New York cardiologist charged in what authorities say was a failed scheme to have another physician hurt or killed is calling the allegations against his client \"completely unsubstantiated.\" Appearing Saturday morning on CNN's \"New Day,\" Randy Zelin defended his client, Dr. Anthony Moschetto, who faces criminal solicitation, conspiracy, burglary, arson, criminal prescription sale and weapons charges in connection to what prosecutors called a plot to take out a rival doctor on Long Island. \"None of anything in this case has any evidentiary value,\" Zelin told CNN's Christi Paul.  \"It doesn't matter what anyone says, he is presumed to be innocent.\" Moschetto,54, pleaded not guilty to all charges Wednesday.  He was released after posting $2 million bond and surrendering his passport. Zelin said that his next move is to get Dr. Moshetto back to work. \"He's got patients to see. This man, while he was in a detention cell, the only thing that he cared about were his patients. And amazingly, his patients were flooding the office with calls, making sure that he was OK,\" Zelin said. Two other men -- identified as James Chmela, 43, and James Kalamaras, 41 -- were named as accomplices, according to prosecutors. They pleaded not guilty in Nassau County District Court, according to authorities. Both were released on bail. A requests for comment from an attorney representing Chmela was not returned. It's unclear whether Kalamaras has retained an attorney. Police officers allegedly discovered approximately 100 weapons at Moschetto's home, including hand grenades, high-capacity magazines and knives. Many of the weapons were found in a hidden room behind a switch-activated bookshelf, according to prosecutors. The investigation began back in December, when undercover officers began buying heroin and oxycodone pills from Moschetto in what was initially a routine investigation into the sale of prescription drugs, officials said. During the course of the undercover operation, however, Moschetto also sold the officers two semiautomatic assault weapons as well as ammunition, prosecutors said. Moschetto allegedly told officers during one buy that he needed dynamite to \"blow up a building.\" He later said he no longer needed the dynamite because a friend was setting fire to the building instead. Kalamaras and Chmela are believed to have taken part in the arson, according to prosecutors. \"The fire damaged but did not destroy the office of another cardiologist whose relationship with Dr. Moschetto had soured due to a professional dispute,\" according to the statement from the district attorney's office. Moschetto allegedly gave an informant and undercover detective blank prescriptions and cash for the assault and killing of the fellow cardiologist, according to prosecutors. He also requested that the rival's wife be assaulted if she happened to be present, authorities said. \"He was willing to pay $5,000 to have him beaten and put in a hospital for a few months, and then he said he would pay $20,000 to have him killed,\" said Assistant District Attorney Anne Donnelly, according to CNN affiliate WCBS.\n",
            "\n",
            "Actual Summary: A lawyer for Dr. Anthony Moschetto says the charges against him are baseless .\n",
            "Moschetto, 54, was arrested for selling drugs and weapons, prosecutors say .\n",
            "Authorities allege Moschetto hired accomplices to burn down the practice of former associate .\n",
            "\n",
            "Predicted Summary: new : randy drexler pleads not guilty to a charge of second - degree murder. new : \" i don't know what to do with my client, \" dr. zelizer says. dr. kermit zakaria is charged with conspiracy to kill and kill his wife. he is accused of making false statements to police.\n",
            "=====================================================================\n",
            "\n",
            "Original Text: (CNN)President Barack Obama took part in a roundtable discussion this week on climate change, refocusing on the issue from a public health vantage point. After the event at Washington's Howard University on Tuesday, Obama sat down with me for a one-on-one interview. I asked him about the science behind climate change and public health and the message he wants the average American to take away, as well as how enforceable his action plan is. Here are five things I learned: . The President enrolled at Occidental College in Los Angeles in 1979 (he transferred to Columbia University his junior year). While in L.A., he said, the air was so bad that it prevented him from running outside. He remembers the air quality alerts and how people with respiratory problems had to stay inside. He credits the Clean Air Act with making Americans \"a lot\" healthier, in addition to being able to \"see the mountains in the background because they aren't covered in smog.\" Obama also said the instances of asthma and other respiratory diseases went down after these measures were taken. Peer-reviewed Environmental Protection Agency studies say that the Clean Air Act and subsequent amendments have reduced early deaths associated with exposure to ambient fine particle pollution and ozone, and reduced illnesses such as chronic bronchitis and acute myocardial infarction. The EPA estimates that, between 1970 and 2010, the act and its amendments prevented 365,000 early deaths from particulate matter alone. \"No challenge poses more of a public threat than climate change,\" the President told me. When I asked about the strength of the science supporting the direct relationship between climate change and public health, he said, \"We know as temperatures rise, insect-borne diseases potentially start shifting up. We know, in a very straight-forward fashion, that heatstroke and other heat-related illnesses and deaths potentially increase, and so what we're doing here is to make sure that in addition to public awareness around the potential for big storms like Hurricane Sandy or big wildfires or droughts, that people recognize there's a very personal, potential impact in climate change, and the good news is we can do something about it.\" In many ways, Obama is attempting to reframe the discussion around climate change as a public health issue that affects all of us, while conceding that we don't fully understand the magnitude of the correlation between rising temperatures and impact on human health. When asked what the average American can do about all this, the President encouraged ordinary citizens, doctors and nurses to start putting some pressure on elected officials \"to try and make something happen to reduce the impacts of climate change.\" He also issued a presidential proclamation declaring April 6-12 as National Public Health Week \"to better understand, communicate and reduce the health impacts of climate change on our communities.\" The average American can also do their part to reduce their own carbon footprint, including: . • Change your incandescent light bulbs to compact fluorescent lights. One CFL can reduce up to 1,300 pounds of carbon dioxide pollution during its lifetime. If every house in the U.S. switched its bulbs, we could reduce the electricity spent on lighting by half. • Unplug your gadgets and chargers when not in use. According to the U.S. Department of Energy, this practice can save $100 a year on your energy bill. • Use a laptop instead of a desktop. Laptops are designed to be energy-efficient, because battery life is a major factor in their design. According to Energy Star, a laptop can be up to 80% more energy-efficient than a desktop. • Filter your own water. Beyond the environmental toll of plastic waste, consider just how far your water was transported before you bought it at the grocery store. • Adjust your curtains and thermostats. If you keep your house 2 degrees warmer in the summer and 2 degrees colder in the winter, you can save big bucks on your energy bill. The Department of Energy estimates you can save up to 15% on your bill by turning off your thermostat when you're not at home. Obama did not appear particularly concerned about the current Supreme Court challenge to the Affordable Care Act. He  said he believes the statute is \"clear and straightforward.\" He said, \"I am not anticipating the Supreme Court would make such a bad decision.\" At issue is the 32 states that did not set up their own health care exchanges and left it to the federal government to do so. The plaintiffs in the lawsuit contend that the language of the Affordable Care Act does not allow for tax subsidies in those states (without state-based exchanges), possibly creating a situation, for example, in which people in Massachusetts would receive a tax credit, but people living in Texas would not. Obama did tell me that if the Supreme Court challenge is upheld, however, there is no Plan B. \"Millions of people would lose their health insurance. They would no longer be able to afford the health insurance that's being provided out there.\" Obama went on to say, \"I think this is the last gasp of folks who have been fighting against [the Affordable Care Act] for ideological reasons.\" He told me that he \"gets letters every day from people who say, 'you know what, the Affordable Care Act saved my life or saved my kid's life because I got insurance.' 'I thought I was healthy; turns out I had a tumor, but because I went and got a checkup, it was removed in time, and I'm now cancer-free.' \" He added, \"I think stories like that will be factored in when the Supreme Court takes a look at this case.\" CNN's Ben Tinker contributed to this report.\n",
            "\n",
            "Actual Summary: \"No challenge poses more of a public threat than climate change,\" the President says .\n",
            "He credits the Clean Air Act with making Americans \"a lot\" healthier .\n",
            "\n",
            "Predicted Summary: president obama says he's aware of the impact of climate change on our lives. he says climate change is the most important issue in the nation's health care system. obama : \" we need to see what we can do to improve our health, \" he says. obama's speech is part of his speech on climate change in washington.\n",
            "=====================================================================\n",
            "\n",
            "Original Text: Moscow (CNN)A Russian TV channel aired Hillary Clinton's first campaign video with a rating stamp that means it's for mature audiences, because of fears it might run afoul of the country's anti-gay propaganda law. A clip of the video, which features a gay couple holding hands, got the 18+ rating from the independent TV Rain channel in Russia on Monday. The channel told CNN that it didn't want to break the controversial law, which bans \"propaganda of nontraditional sexual relations around minors\" and bars public discussion of gay rights and relationships within earshot of children. \"There are no legal precedents for this law, so we just don't know what comes under this law and (what) doesn't,\" a TV Rain spokesperson told CNN. \"Therefore, fearing to break the law -- especially given the high attention to TV Rain from the supervising authorities -- we decided to put a marker (on the video).\" Clinton's video was released over the weekend to announce the start of her 2016 U.S. presidential campaign. It features about five seconds of two men holding hands. One of the men says, \"I'm getting married this summer to someone I really care about.\" The former senator and first lady first declared her support for same-sex marriage in early 2013, saying that \"gay rights are human rights, and human rights are gay rights.\" Russia's controversial law caused an international outcry after it was passed by the Russian Parliament and signed by President Vladimir Putin in July 2013. Human Rights Watch described the anti-gay propaganda law as \"a profoundly discriminatory and dangerous bill that is bound to worsen homophobia in Russia.\" Rights campaigners called for a boycott of the 2014 Winter Olympics in Sochi, and a number of bars around the world stopped serving Russian vodka in protest. U.S. President Barack Obama -- Clinton's former boss -- said at the time that he found the legislation offensive. \"I have no patience for countries that try to treat gays or lesbians or transgendered persons in ways that intimidate them or harmful to them,\" Obama told Jay Leno in 2013. Putin defended the law, noting that unlike other countries, Russia decriminalized homosexual relationships (in 1993). \"We don't outlaw anything and don't nab anyone,\" he said before the 2014 Games. \"That's why you can feel safe and free here,\" he added, \"but please leave our children in peace.\" The rights group ILGA-Europe said in a May 2014 report that Russia was the worst place in Europe (out of 49 countries) for LGBTI people to live. READ MORE: Social media react to Hillary Clinton logo .\n",
            "\n",
            "Actual Summary: Presidential hopeful's video, featuring gay couple, gets mature rating in Russia .\n",
            "Russian TV channel feared airing it would break the country's anti-gay propaganda law .\n",
            "Clinton announced her support for same-sex marriage in 2013 .\n",
            "\n",
            "Predicted Summary: new : russia's president calls the video \" a propaganda stunt \" new : clinton says it's not the first time the video shows gays in public. new : putin says the video is a violation of the u. s. constitution. the white house says it is considering a ban on gays and lesbians.\n",
            "=====================================================================\n",
            "\n",
            "Original Text: (CNN)Marco Rubio is all in.  The Republican senator from Florida has announced that he is seeking the Republican presidential nomination, running on an optimistic message that he embodies the promise of the American Dream. With his youthful energy and Hispanic roots, it's tempting to see Rubio as the new blood that the GOP needs in order to compete against Hillary Clinton in 2016.  Yet Rubio has been his own worst enemy on what could have been his two signature issues: immigration reform and Cuba relations.  He holds little appeal to Latino voters.  And unless he can offer new ideas, his climb to the Republican nomination will be steep. Back in 2013, Rubio was a member of the Senate \"Gang of 8\" that crafted a bipartisan proposal for comprehensive reform, including a path to citizenship for the nation's estimated 11 million undocumented immigrants.  He later distanced himself from the bill after it ran into resistance from House Republicans, and now says he favors a piecemeal approach, starting with securing the border. His retreat on immigration means that Rubio has missed an opportunity to set himself apart from most of the presumptive Republican presidential candidates.  That's a shame, for this issue was supposed to be his calling card to Latino voters. Instead, Rubio has embraced a typical conservative approach to immigration.   He believes that President Obama's Deferred Action program, offering deportation relief to young immigrants, should be ended.  He has stated that the President's executive action on immigration, on hold pending a circuit court review, sets a \"horrifying precedent.\" Meanwhile, both the Deferred Action program and President Obama's executive action on immigration are overwhelmingly favored by Hispanics.  No wonder the research firm Latino Decisions reports that, \"We find no evidence that Rubio's candidacy will draw significant Latino support for his candidacy or for his party more generally.\"  So, if Rubio is counting on his ethnicity and personal history as the son of immigrants to win over fellow Hispanics, he is mistaken. At a private breakfast Monday for supporters, Rubio described running against \"one candidate in the race who's from yesterday, and one who wants to take us back to yesterday.\"  But when it comes to Cuba policy, Rubio himself seems firmly stuck in the past.  Over the weekend, he called the recent thaw in relations between the two countries ridiculous. He has warned that Cuba is taking advantage of the United States.  Here, he is an increasingly lonely voice.  Most Americans support better relations with Cuba, as do a majority of Cuban-Americans.  By clinging to the notion that isolating Cuba is better than engaging with the communist country, Rubio has marginalized himself on an issue where he could have provided insight and leadership. Immigration and Cuba policy aside, Rubio's political philosophy will be a tough sell to Hispanics.  He is a fierce opponent of \"Obamacare\" and wants the law repealed.  However, the Affordable Care Act has led to a 12.3% drop in the Hispanic uninsured rate, making Latinos the demographic with the largest gain in insurance, thanks to the law.  (In fact, Rubio signed his own family up for \"Obamacare\" on the Washington exchange, taking advantage of a generous federal subsidy offered to lawmakers.) Rubio favors smaller government, while Latinos are more likely than the general public to say they favor a bigger government that provides more services over a small government that provides less.  And though Rubio doubts that climate change is caused by humans, The New York Times has noted that Latinos view global warming as a problem and favor government action on the issue. Sure, Rubio is young and charismatic.  But his work on the failed immigration bill notwithstanding, Rubio has a significant lack of accomplishments to show for his five years in the senate.  In February, he was reported as topping the list of absentee lawmakers by the website Politico. Another Rubio weakness is his lack of bold policy proposals.  Consider that his fellow contender for the GOP presidential nomination, Sen. Rand Paul of Kentucky, has been willing to present new ideas to the Republican base, such as reforming the criminal justice system and legalizing medical marijuana.  Or that another GOP candidate for president, Sen. Ted Cruz  of Texas is entirely comfortable with his image as a conservative firebrand.  By comparison, Rubio seems cautious and ill-suited to the task of rousing Republican voters. With his early leap into the 2016 race, Marco Rubio is positioning himself as the next generation of GOP leadership.  Unfortunately, a fresh face on stale ideas is not a winning combination -- not for Rubio, and not for Latino voters.\n",
            "\n",
            "Actual Summary: Raul Reyes: In seeking Latino vote, Marco Rubio his own worst enemy on two key issues: immigration reform, Cuba relations .\n",
            "He says on health care, climate change and other issues, he breaks from Latinos' positions. Polls show they don't favor him .\n",
            "\n",
            "Predicted Summary: ruben navarrette : rubio's 2016 bid to win the u. s. senate nomination. he says rubio has a long history of support for immigration reform. navarrette says he's not the only candidate in the race for the 2016 nomination. but he says he doesn't want to go to the polls for the first time in a decade.\n",
            "=====================================================================\n",
            "\n",
            "Original Text: (CNN)SPOILER ALERT! It's not just women getting cloned. That was the big twist at the end of \"Orphan Black's\" second season. The kickoff to the new season leads the list of six things to watch in the week ahead. 1. \"Orphan Black,\" 9 p.m. ET, Saturday, April 18, BBC America . The cloning cult sci-fi series remains one of the most critically acclaimed shows on TV, thanks in large part to the performance of Tatiana Maslany, who has taken on at least six roles on the show so far, including a newly introduced transgender clone. Maslany told reporters this week that we can expect even more impressive scenes with multiple clones. \"We like to push the boundaries of what we're able to do and the limits of those clone scenes,\" she said. \"So, yes, you'll definitely see more complex clone work this season and that's just because we're getting more comfortable with the technology and we're excited by getting to sort of further complicate things.\" And the introduction of a group of male clones will certainly increase the suspense. \"There definitely is a shift towards the Castor clones that we get to explore them a little bit more,\" she said. The fans of the show, dubbed the \"Clone Club\" have a lot to look forward to when the show premieres on Saturday the 18th, and Maslany is blown away by the response to the series so far. \"We've always been really humbled and really inspired by our fans and by their dedication to the show and their knowledge of the show, and  just how it changes their own lives. It's incredible.\" 2. \"Turn: Washington's Spies,\" 9 p.m. ET, Monday, AMC . The series about spies in the early days of the Revolutionary War returns with a new subtitle, \"Washington's Spies,\" and a new Monday night time slot. Series star Jamie Bell told CNN what we can expect in the second season. \"This year we have a lot more battles; we have the journey of [George] Washington and we're getting under his skin a little bit as well. We also introduce new characters like Benedict Arnold, a very infamous character in American history.\" Bell hopes the series might bring more recognition to the Culper spy ring and everything it did. \"I think there should be a monument to all of the Culper ring somewhere. I was amazed that there is nothing [in Washington] about these people who did something extraordinary.\" 3. \"Game of Thrones,\" 9 p.m. ET, Sunday, HBO . The world of Westeros returns for a fifth season in one of the biggest season premieres of the year. Click here for more on what to expect. 4. \"Justified,\" 10 p.m. ET, Tuesday, FX . Timothy Olyphant's tour de force performance as Raylan Givens comes to an end Tuesday night, as the modern-day Western airs its season finale. We'll have to see how his final showdown with Boyd Crowder goes. 5. \"Veep,\" 10:30 ET, Sunday, HBO . Hugh Laurie joins the cast and Julia Louis-Dreyfus is now the president of the United States on HBO's hit comedy. 6. \"Nurse Jackie,\" 9 p.m. ET, Sunday, Showtime . The final season of Showtime's long-running melodrama begins.\n",
            "\n",
            "Actual Summary: Critically acclaimed series \"Orphan Black\" returns .\n",
            "\"Turn: Washington's Spies\" starts a second season .\n",
            "\"Game of Thrones\" is back for season five .\n",
            "\n",
            "Predicted Summary: the new series will air on fox's \" sci fi academy \" it'll be the first episode of \" the secret agent \" the series will feature a female lead and a male lead. it's the first time the series has been renewed for a second season.\n",
            "=====================================================================\n",
            "\n",
            "Original Text: (CNN)Emergency operators get lots of crazy calls, but few start like this. Caller:  \"Hello, I'm trapped in this plane and I called my job, but I'm in this plane.\" Operator:  \"You're where?\" Caller:  \"I'm inside a plane and I feel like it's up moving in the air.  Flight 448 can you please tell somebody (to) stop it.\" The frantic 911 call came just as the Alaska Airlines flight had taken off from Seattle-Tacoma International Airport on Monday afternoon.  The caller was a ramp agent who fell asleep in the plane's cargo hold. The cell phone call soon broke up, but the man was making himself known in other ways as the crew and passengers reported unusual banging from the belly of the Boeing 737. The pilot radioed air traffic control and said he would make an emergency landing. \"There could be a person in there so we're going to come back around,\" he told air traffic control. The ramp agent who took the untimely nap and caused all the fuss is an employee of Menzies Aviation, a contractor for Alaska Airlines that handles loading the luggage. He'll no longer have the option of dozing aboard one of the airline's planes. \"The Menzies employee has been permanently banned from working on Alaska Airlines planes,\" said Bobbie Egan, a spokeswoman for the airline. Flight 448, which was on its way to Los Angeles, only spent 14 minutes in the air. Other than being scared, the agent never was in any real danger. The cargo hold is pressurized and temperature controlled, the airline said. The passengers knew something wasn't right, almost as soon as the plane took off. \"All of a sudden we heard all this pounding underneath the plane and we thought there was something wrong with the landing gear,\" Robert Higgins told CNN affiliate KABC. Not everyone heard the banging, but it was soon clear this wasn't a normal flight. \"We just took off for L.A. regular and then ... about five minutes into the flight the captain came on and said we were going back and we'd land within five to seven minutes, and we did,\" passenger Marty Collins told affiliate KOMO. \"When we landed was when all the trucks and the police and the fire trucks surrounded the plane.\" \"I think it's scary and really unsafe, too,\" Chelsie Nieto told affiliate KCPQ. \"Because what if it's someone who could have been a terrorist?\" The employee started work at 5 a.m. and his shift was scheduled to end at 2:30 p.m., just before the flight departed. The agent was off the two days prior to the incident and had taken a lunch break and a break in the afternoon before making his way into the cargo hold, according to a source familiar with the investigation. The man had been on a four-person team loading baggage onto the flight. \"During a pre-departure huddle, the team lead noticed the employee was missing. The team lead called into the cargo hold for the employee and called and texted the employee's cell phone, but did not receive an answer. His co-workers believed he finished his shift and went home,\" the airline's blog said. It's believed he was hidden by luggage, making it difficult for the rest of his team to see him, the source said. All ramp employees have security badges, and undergo full criminal background checks before being hired, according to the airline. After the delay, the flight with 170 passengers and six crew members on board made it to Los Angeles a couple of hours late. CNN's Dave Alsup, Joshua Gaynor and Greg Morrison contributed to this report.\n",
            "\n",
            "Actual Summary: The ramp agent fell asleep in the plane's cargo hold .\n",
            "He can no longer work on Alaska Airlines flights .\n",
            "\n",
            "Predicted Summary: new : the flight attendant says he's sorry for the incident. the flight was headed to los angeles, where he was waiting for the flight. the man was trying to get away from the plane's landing gear, the faa says. the incident occurred during a routine emergency landing at a los angeles airport.\n",
            "=====================================================================\n",
            "\n",
            "Original Text: (CNN)Mullah Mohammed Omar is \"still the leader\" of the Taliban's self-declared Islamic Emirate of Afghanistan. That appears to be the primary message of a biography, just published by the Taliban, of the reclusive militant who is credited with founding the group in the early 1990s. The Taliban's \"Cultural Commission\" released the 11-page document in several different translations on the movement's website, ostensibly to commemorate the 19th anniversary of an April 4, 1996, meeting in Afghanistan's Kandahar province when an assembly of Afghans swore allegiance to Omar. Several Afghan observers say the biography is aimed at dispelling rumors of Omar's demise. \"There have been a lot of rumors lately about him. Some people are saying that he is not alive,\" said Sayyed Muhammad Akbar Agha, a former Taliban insider who has written an autobiography about his days with the movement. \"I think the Taliban thought it was an important time to release his biography to give assurances that he is alive and present,\" Agha told CNN in a telephone interview. Bergen: Why U.S. must stay in Afghanistan past 2016 . The biography also appears to be an attempt to remind the world of the Afghan's jihadi leadership credentials, at a time when ISIS leader Abu Bakr al-Baghdadi has declared himself \"caliph\" of the world's Muslims. \"The Taliban has a huge leadership problem at a critical political moment,\" said Graeme Smith, a Kabul-based analyst for the International Crisis Group. \"Another caliph has announced himself to the world, and the Taliban has been silent. And that is getting noticed by militants across South Asia.\" Omar was famously camera-shy during the Taliban's six-year rule over most of Afghanistan. To this day, there are only a handful of photographs of the one-eyed leader. \"He never was actively involved in any of these propaganda campaigns. No publicity. No interviews. He never used the Internet,\" said Rahimullah Yusufzai, a Pakistani journalist and expert on Afghanistan who once interviewed Osama bin Laden. Omar then all but disappeared after a U.S.-led bombing campaign routed the Taliban from Kabul in 2001. Washington has offered a $10 million reward for his capture. The Taliban have released written statements purportedly made by the leader-in-hiding. But years without any video or audio recordings of the fugitive have led to growing speculation that Omar may have died. The biography challenges rumors of Omar's death by offering a description of his daily work schedule, which begins with prayers, study of the Quran, and then delivering \"orders in a specific way to his Jihadi commanders.\" The publication also seeks to fill in some of the gaps about the militant's early years, including the detail that his \"preferred weapon of choice\" was the RPG-7, a rocket-propelled grenade. According to the biography, Omar was born in 1960 in a village called Chah-i-Himmat in Afghanistan's Kandahar province. His father, a \"well-known and respected erudite and social figure,\" died only five years later, apparently of natural causes. Omar studied at a religious school, or madrassa, run by his uncle. The rise of the Communist Party in Afghanistan, and the subsequent 1979 Soviet invasion, interrupted the young man's studies and propelled him into the arms of the armed Afghan opposition known as the mujahedeen. For the next decade, Omar commanded rebel groups \"against the invading Russians and their internal communist puppets,\" according to the biography. Along the way, he was wounded a number of times and was blinded in his right eye. In one battle, the biography claims, Omar and a fighter named Mullah Biradar Akhund destroyed four Soviet tanks, even though they were armed with only four RPG rounds. The Taliban biography makes no mention of the fact that the U.S., allied with Saudi Arabia and Pakistan, helped arm and bankroll the mujahedeen until the Soviet army withdrew in defeat in 1989. Afghan historians have documented the rapid rise of the Taliban in the chaotic years after the communist government in Kabul collapsed in 1992. The movement of warriors who identified themselves as religious scholars emerged to bring order to a country being ripped apart by rival mujahedeen warlords who battled one another for power. The Taliban biography says that Omar and his compatriots \"launched their struggle and fight against corruption and anarchy\" after an initial meeting in Kandahar in June 1994. Two years later, the Taliban captured Kabul and began imposing its austere interpretation of Islamic law on the rest of the country. While the document denounces the Taliban's post-9/11 overthrow at the hands of a U.S.-backed coalition of rival Afghan fighters, it makes no mention of the Taliban's alliance with bin Laden and al Qaeda. During a decade in exile, the Saudi-born bin Laden continued to release periodic video and audio statements until he was killed by U.S. raid on his hideout in the Pakistani city of Abbottabad in 2011. Though Taliban militants have continued to battle the U.S.-backed government across Afghanistan, Omar has not been seen or heard from in years. The movement claims he continues to oversee a Taliban leadership council, judiciary and nine executive commissions, as well as military commanders who operate in all 34 provinces of Afghanistan. Exclusive: ISIS 'recruits Afghans' in chilling video . CNN's Masoud Popalzai contributed to this report from Kabul, Afghanistan.\n",
            "\n",
            "Actual Summary: Mullah Omar, the reclusive founder of the Afghan Taliban, is still in charge, a new biography claims .\n",
            "An ex-Taliban insider says there have been rumors that the one-eyed militant is dead .\n",
            "\n",
            "Predicted Summary: mullah omar's latest book, \" jihad, \" has been released in the united states. the book is part of a long tradition of publishing the book. the taliban claim responsibility for the book's release, but the taliban denies it. mullah's book is the latest in a long line of criticism from the taliban.\n",
            "=====================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG3sJch-7GeR",
        "outputId": "f1c054f7-b0e0-4bc7-abef-7e96d396ca2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "print(rouge_output)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score(precision=0.03913796113227547, recall=0.06732131280287557, fmeasure=0.04840349920181923)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zdm50ZotZqb"
      },
      "source": [
        "The fully trained *BERT2BERT* model is uploaded to the 🤗model hub under [patrickvonplaten/bert2bert_cnn_daily_mail](https://huggingface.co/patrickvonplaten/bert2bert_cnn_daily_mail). \n",
        "\n",
        "The model achieves a ROUGE-2 score of **18.22**, which is even a little better than reported in the paper.\n",
        "\n",
        "For some summarization examples, the reader is advised to use the online inference API of the model, [here](https://huggingface.co/patrickvonplaten/bert2bert_cnn_daily_mail)."
      ]
    }
  ]
}