# Fine-tune-Transformer-summarization

The repo stores code as part of the graduate research project for MCS of CSUN. 

The research uses several pretrained transformers, downstreaming and fine-tuning to summarization tasks.

Including T5, T5-small, BART, Pegasus, BERT, distillBERT, etc..