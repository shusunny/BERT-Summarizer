# Fine-tune-Transformer-summarization

The repo stores code as part of the graduate research project for MCS of CSUN.

The research uses several pretrained transformers checkpoints from Huggingface API, downstreaming and fine-tuning to text summarization tasks.

Assessments include T5, T5-small, BART, Encoder-Decoder model with bert, and ProphetNet. 

For more information, check CSU ScholarWorks "FINE-TUNING TRANSFORMERS: ASSESSMENTS OF TRANSFORMER-BASED MODELS DOWNSTREAM TO TEXT SUMMARIZATION"