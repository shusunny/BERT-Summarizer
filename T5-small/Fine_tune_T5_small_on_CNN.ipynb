{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-tune T5-small on CNN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "98f11ed030cb467abee66a6bb4ecd3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29f7a909e5af49e8a6ba74cc073bfdbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_29f8e65958224601a8625c7d0c86aa28",
              "IPY_MODEL_72a9323f4c014774b5aec58b2eda9513",
              "IPY_MODEL_06faf452d2bc436e8a86ce062571dc23"
            ]
          }
        },
        "29f7a909e5af49e8a6ba74cc073bfdbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29f8e65958224601a8625c7d0c86aa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55504b4bc9794c5c94fe676771f2a724",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38c8c95b007c4586a3eb3a52b849c99a"
          }
        },
        "72a9323f4c014774b5aec58b2eda9513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa48aa7b9ab14533a5b3b6582aeffdd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9417117d4ae34722855c5126438aa07a"
          }
        },
        "06faf452d2bc436e8a86ce062571dc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bf1081b70af64e078d741b151b04d2e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 68.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c07a9df03ffa4c0ab596b7b261e327c1"
          }
        },
        "55504b4bc9794c5c94fe676771f2a724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38c8c95b007c4586a3eb3a52b849c99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa48aa7b9ab14533a5b3b6582aeffdd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9417117d4ae34722855c5126438aa07a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf1081b70af64e078d741b151b04d2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c07a9df03ffa4c0ab596b7b261e327c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e597c57c42844fe58ed9de129361b4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c9fea5c2e40349988f708090a0026c8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df47e1b6a40a45b49fd23c07aeaeaeb9",
              "IPY_MODEL_ad5037c5d3e448bf98bf391268a0ffab",
              "IPY_MODEL_08ccbd0a6c094846b1e31d3efea47f93"
            ]
          }
        },
        "c9fea5c2e40349988f708090a0026c8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df47e1b6a40a45b49fd23c07aeaeaeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b446f1b741c646ba926539dc8e397007",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4b641c2292d4993a4cc2db3214dcf27"
          }
        },
        "ad5037c5d3e448bf98bf391268a0ffab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dacefa86dfd440539b75f23d4696ad1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ea34de70a964f8281857d54a31d8a67"
          }
        },
        "08ccbd0a6c094846b1e31d3efea47f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a5c1c31eded469e8af6aa0ebca1695e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14/14 [00:24&lt;00:00,  1.33s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e89c5b4e8c14b7ca24f72471c144f3a"
          }
        },
        "b446f1b741c646ba926539dc8e397007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4b641c2292d4993a4cc2db3214dcf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dacefa86dfd440539b75f23d4696ad1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ea34de70a964f8281857d54a31d8a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a5c1c31eded469e8af6aa0ebca1695e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e89c5b4e8c14b7ca24f72471c144f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUGbYz84pdUH"
      },
      "source": [
        "# Fine-tune T5-small on CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n47c6hknp4Tc"
      },
      "source": [
        "## Libraries and environment preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOsHUjgdIrIW"
      },
      "source": [
        "#Install essential packages\n",
        "%%capture\n",
        "! pip install datasets transformers rouge-score nltk wandb\n",
        "!apt install git-lfs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRR_NvOdahp_",
        "outputId": "e97f62c1-ce83-48c9-dc7b-ade63d59f33f"
      },
      "source": [
        "#Colab Environment Check for GPU and RAM\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "#GPU check\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "Fri Feb  4 00:43:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd2tIC7g0UHT"
      },
      "source": [
        "Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glZC8RTP0UHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee61ddd8-90aa-4dbe-865a-311a810b91f9"
      },
      "source": [
        "# Make sure your version of Transformers is at least 4.11.0 \n",
        "# to run the following code correctly:\n",
        "import transformers\n",
        "import datasets\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.16.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8-hXSR0i-zy"
      },
      "source": [
        "# Import Wandb \n",
        "import os\n",
        "import wandb\n",
        "API_KEY = '39991c538626bee25c64d4f8a4c3403dd635537c'\n",
        "os.environ[\"WANDB_API_KEY\"] = API_KEY"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whPRbBNbIrIl"
      },
      "source": [
        "## Loading the dataset and process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IreSlFmlIrIm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "98f11ed030cb467abee66a6bb4ecd3db",
            "29f7a909e5af49e8a6ba74cc073bfdbd",
            "29f8e65958224601a8625c7d0c86aa28",
            "72a9323f4c014774b5aec58b2eda9513",
            "06faf452d2bc436e8a86ce062571dc23",
            "55504b4bc9794c5c94fe676771f2a724",
            "38c8c95b007c4586a3eb3a52b849c99a",
            "aa48aa7b9ab14533a5b3b6582aeffdd4",
            "9417117d4ae34722855c5126438aa07a",
            "bf1081b70af64e078d741b151b04d2e3",
            "c07a9df03ffa4c0ab596b7b261e327c1"
          ]
        },
        "outputId": "5ec0ea60-891d-4090-ba8d-4f15c8021055"
      },
      "source": [
        "raw_datasets = datasets.load_dataset('cnn_dailymail', '3.0.0')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98f11ed030cb467abee66a6bb4ecd3db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWiVUF0jIrIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea90bb1b-2086-44b9-954e-1b5a0407dbec"
      },
      "source": [
        "raw_datasets"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90DOtlCDk07d"
      },
      "source": [
        "model_checkpoint = \"t5-small\"\n",
        "from transformers import T5TokenizerFast\n",
        "tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLQtq0Ac0UHc"
      },
      "source": [
        "# If you are using one of the five T5 checkpoints we have to prefix \n",
        "# the inputs with \"summarize:\" (t5 is a multi-task model).\n",
        "\n",
        "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
        "    prefix = \"summarize: \""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc0BSBLIIrJQ"
      },
      "source": [
        "# tokenlize inputs into map\n",
        "\n",
        "max_input_length = 512\n",
        "max_target_length = 128\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + doc for doc in examples[\"article\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"highlights\"], max_length=max_target_length, truncation=True)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e597c57c42844fe58ed9de129361b4eb",
            "c9fea5c2e40349988f708090a0026c8c",
            "df47e1b6a40a45b49fd23c07aeaeaeb9",
            "ad5037c5d3e448bf98bf391268a0ffab",
            "08ccbd0a6c094846b1e31d3efea47f93",
            "b446f1b741c646ba926539dc8e397007",
            "c4b641c2292d4993a4cc2db3214dcf27",
            "dacefa86dfd440539b75f23d4696ad1b",
            "0ea34de70a964f8281857d54a31d8a67",
            "1a5c1c31eded469e8af6aa0ebca1695e",
            "2e89c5b4e8c14b7ca24f72471c144f3a"
          ]
        },
        "id": "f5taYLq5gZ7r",
        "outputId": "c5dd7ce5-36bf-4e8e-b8c0-a59351e89f39"
      },
      "source": [
        "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-050c2bd6f70abd9a.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e597c57c42844fe58ed9de129361b4eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/14 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-48bc424f15731890.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyGLN12Ue8Qq",
        "outputId": "30ae43a2-2f42-45fc-c54d-cb80e738c88c"
      },
      "source": [
        "tokenized_datasets"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 287113\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 13368\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['article', 'highlights', 'id', 'input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 11490\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "545PP3o8IrJV"
      },
      "source": [
        "## Fine-tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMgPYCXKcQig"
      },
      "source": [
        "# Import Huggingface Automodel class from model checkpoint and print details\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryalV2iH0UHe"
      },
      "source": [
        "# data collator: pad the inputs and labels during each batch to save space\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep track with wandb\n",
        "wandb.init(project=\"T5-small-cnn\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "A9vKcn6u6Osg",
        "outputId": "f926d51e-6583-4024-9765-c3090c15e0f4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshusunny\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/shusunny/T5-small-cnn/runs/3riotdcy\" target=\"_blank\">sleek-dragon-2</a></strong> to <a href=\"https://wandb.ai/shusunny/T5-small-cnn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f003fd03810>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/shusunny/T5-small-cnn/runs/3riotdcy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sZOdRlRIrJd"
      },
      "source": [
        "Define `Seq2SeqTrainer` to compute the metrics from the predictions, and also do a bit of pre-processing to decode the predictions into texts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmvbnJ9JIrJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449eb5be-3e5c-41f0-a674-e6cc62be2fd0"
      },
      "source": [
        "# Define compute_metrics\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "\n",
        "metric = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Mlb63H0UHe"
      },
      "source": [
        "# Define traing args, batch size and epoch\n",
        "# batch size max 8 for input length 1024 on Colab Pro\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 1\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-cnn\",\n",
        "    load_best_model_at_end=\"eval_loss\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=1e-3,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    logging_steps=1000,  # set to 1000 for full training\n",
        "    save_steps=1250,  # set to 500 for full training\n",
        "    eval_steps=1250,  # set to 8000 for full training\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=epochs,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    report_to=\"wandb\",\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imY1oC3SIrJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff939e03-7c74-4018-af09-2d3d53031e23"
      },
      "source": [
        "# Pass into the trainer\n",
        "\n",
        "train_dataset=tokenized_datasets[\"train\"]\n",
        "eval_dataset=tokenized_datasets[\"validation\"]\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdzABDVcIrJg"
      },
      "source": [
        "We can now finetune our model by just calling the `train` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNx5pyRlIrJh",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74cdf962-174a-4929-a9c9-e319b271f5ec"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 287113\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 17945\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17945' max='17945' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17945/17945 3:48:34, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>2.196400</td>\n",
              "      <td>1.936945</td>\n",
              "      <td>24.112200</td>\n",
              "      <td>11.271500</td>\n",
              "      <td>19.876600</td>\n",
              "      <td>22.687500</td>\n",
              "      <td>18.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.164300</td>\n",
              "      <td>1.919584</td>\n",
              "      <td>24.038400</td>\n",
              "      <td>11.317700</td>\n",
              "      <td>19.825800</td>\n",
              "      <td>22.746300</td>\n",
              "      <td>18.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>2.162600</td>\n",
              "      <td>1.891030</td>\n",
              "      <td>24.146600</td>\n",
              "      <td>11.333100</td>\n",
              "      <td>19.891300</td>\n",
              "      <td>22.799500</td>\n",
              "      <td>18.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.115500</td>\n",
              "      <td>1.882262</td>\n",
              "      <td>24.032900</td>\n",
              "      <td>11.321600</td>\n",
              "      <td>19.838900</td>\n",
              "      <td>22.631100</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>2.103000</td>\n",
              "      <td>1.866311</td>\n",
              "      <td>24.230300</td>\n",
              "      <td>11.395000</td>\n",
              "      <td>19.927500</td>\n",
              "      <td>22.811700</td>\n",
              "      <td>18.999700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>2.079300</td>\n",
              "      <td>1.851798</td>\n",
              "      <td>24.404500</td>\n",
              "      <td>11.589700</td>\n",
              "      <td>20.102600</td>\n",
              "      <td>22.989800</td>\n",
              "      <td>18.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>2.077400</td>\n",
              "      <td>1.835055</td>\n",
              "      <td>24.356700</td>\n",
              "      <td>11.596900</td>\n",
              "      <td>20.090200</td>\n",
              "      <td>22.923600</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>2.054500</td>\n",
              "      <td>1.828629</td>\n",
              "      <td>24.318500</td>\n",
              "      <td>11.512700</td>\n",
              "      <td>20.052700</td>\n",
              "      <td>22.954000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11250</td>\n",
              "      <td>2.041700</td>\n",
              "      <td>1.825096</td>\n",
              "      <td>24.236200</td>\n",
              "      <td>11.608300</td>\n",
              "      <td>20.050700</td>\n",
              "      <td>22.868100</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>2.033200</td>\n",
              "      <td>1.802971</td>\n",
              "      <td>24.392600</td>\n",
              "      <td>11.625500</td>\n",
              "      <td>20.182800</td>\n",
              "      <td>23.019100</td>\n",
              "      <td>18.999900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13750</td>\n",
              "      <td>2.015900</td>\n",
              "      <td>1.803488</td>\n",
              "      <td>24.316500</td>\n",
              "      <td>11.646300</td>\n",
              "      <td>20.105900</td>\n",
              "      <td>22.968200</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15000</td>\n",
              "      <td>1.996000</td>\n",
              "      <td>1.790215</td>\n",
              "      <td>24.506100</td>\n",
              "      <td>11.729600</td>\n",
              "      <td>20.230400</td>\n",
              "      <td>23.113400</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16250</td>\n",
              "      <td>2.004400</td>\n",
              "      <td>1.788842</td>\n",
              "      <td>24.495700</td>\n",
              "      <td>11.749100</td>\n",
              "      <td>20.263900</td>\n",
              "      <td>23.132000</td>\n",
              "      <td>18.999800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17500</td>\n",
              "      <td>1.987800</td>\n",
              "      <td>1.781395</td>\n",
              "      <td>24.564400</td>\n",
              "      <td>11.767800</td>\n",
              "      <td>20.316200</td>\n",
              "      <td>23.196600</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-1250\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-1250/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-1250/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-1250/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-1250/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-2500\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-2500/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-2500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-1000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-3750\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-3750/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-3750/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-3750/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-3750/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-2000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-5000\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-5000/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-5000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-1250] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-6250\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-6250/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-6250/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-6250/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-6250/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-2500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-7500\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-7500/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-7500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-7500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-7500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-3750] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-8750\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-8750/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-8750/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-8750/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-8750/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-5000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-10000\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-10000/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-10000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-10000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-10000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-6250] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-11250\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-11250/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-11250/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-11250/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-11250/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-7500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-12500\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-12500/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-12500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-12500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-12500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-8750] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-13750\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-13750/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-13750/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-13750/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-13750/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-10000] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-15000\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-15000/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-15000/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-15000/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-15000/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-11250] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-16250\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-16250/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-16250/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-16250/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-16250/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-12500] due to args.save_total_limit\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: article, id, highlights.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 13368\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to t5-small-finetuned-cnn/checkpoint-17500\n",
            "Configuration saved in t5-small-finetuned-cnn/checkpoint-17500/config.json\n",
            "Model weights saved in t5-small-finetuned-cnn/checkpoint-17500/pytorch_model.bin\n",
            "tokenizer config file saved in t5-small-finetuned-cnn/checkpoint-17500/tokenizer_config.json\n",
            "Special tokens file saved in t5-small-finetuned-cnn/checkpoint-17500/special_tokens_map.json\n",
            "Deleting older checkpoint [t5-small-finetuned-cnn/checkpoint-13750] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from t5-small-finetuned-cnn/checkpoint-17500 (score: 1.7813949584960938).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=17945, training_loss=2.0680589303361834, metrics={'train_runtime': 13714.6917, 'train_samples_per_second': 20.935, 'train_steps_per_second': 1.308, 'total_flos': 3.885839064603034e+16, 'train_loss': 2.0680589303361834, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb5m_jbmR3ub"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl9lSry5vNgz",
        "outputId": "588b3491-112f-4199-9687-4bd84a6a276c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls t5-small-finetuned-cnn/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Hsz85nhKzW",
        "outputId": "4e5d583d-a0d4-4fc0-82f1-194adfa040a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-15000  checkpoint-16250  checkpoint-17500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/t5-small-finetuned-cnn.zip /content/t5-small-finetuned-cnn/checkpoint-17500/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6euKZFlAujxk",
        "outputId": "cf7939c5-51af-49c1-8445-c8a360529c0a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/ (stored 0%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/scheduler.pt (deflated 49%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/training_args.bin (deflated 49%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/scaler.pt (deflated 55%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/tokenizer_config.json (deflated 80%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/special_tokens_map.json (deflated 83%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/trainer_state.json (deflated 80%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/config.json (deflated 62%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/optimizer.pt (deflated 7%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/tokenizer.json (deflated 74%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/rng_state.pth (deflated 27%)\n",
            "  adding: content/t5-small-finetuned-cnn/checkpoint-17500/pytorch_model.bin (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp t5-small-finetuned-cnn.zip '/content/drive/My Drive/weights/'"
      ],
      "metadata": {
        "id": "tX9i01SN1W7P"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}